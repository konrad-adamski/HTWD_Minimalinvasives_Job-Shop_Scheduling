{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931bc80c98da12ed",
   "metadata": {},
   "source": [
    "# Rescheduling mit Lateness"
   ]
  },
  {
   "cell_type": "code",
   "id": "8c164548-721b-4931-8186-56b5a5c544fe",
   "metadata": {},
   "source": [
    "from configs.config import get_path\n",
    "import src.utils.converter as convert\n",
    "import src.utils.presenter as show\n",
    "import src.utils.checker as check\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 21)\n",
    "\n",
    "import src.utils.gen_jobs as gen_jobs\n",
    "import src.utils.gen_deadline as gen_deadline\n",
    "import src.utils.rolling_scheduling as rolling_schedule\n",
    "\n",
    "import src.models.cp.lateness as solver\n",
    "import src.models.heuristics.fcfs as heuristics\n",
    "\n",
    "import numpy as np\n",
    "from ortools.sat.python import cp_model\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f6a1202420181e2",
   "metadata": {},
   "source": [
    "max_time = 60 * 45 # 45 min\n",
    "max_time = 60 * 5 # 5 min"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df9e842494089b55",
   "metadata": {},
   "source": [
    "basic_data_path = get_path(\"data\", \"basic\")\n",
    "df_instance = pd.read_csv(basic_data_path / \"00_instance.csv\")\n",
    "\n",
    "df_ops, df_jobs_arrivals = gen_jobs.create_jobs_for_days(df_instance, day_count = 1, u_b_mmax= 0.94, shuffle = True)\n",
    "df_ops"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32d6297f58247d17",
   "metadata": {},
   "source": [
    "# a) Initialisierung der Deadlines\n",
    "df_jobs = gen_deadline.get_times_df(df_ops, df_jobs_arrivals, heuristics.schedule_fcfs_with_arrivals, target_service=1.0)\n",
    "\n",
    "# Rundung für CP \n",
    "df_jobs[\"Arrival\"] = np.floor(df_jobs[\"Arrival\"]).astype(int)\n",
    "df_jobs[\"Deadline\"] = np.ceil(df_jobs[\"Deadline\"]).astype(int)\n",
    "df_jobs.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aec5c154-c423-4882-988b-0e41e91ccf9f",
   "metadata": {},
   "source": [
    "# b) Bestimmung der \"Ready Time\"\n",
    "df_jobs['Ready Time'] = ((df_jobs['Arrival'] // 1440) + 1) * 1440\n",
    "\n",
    "# c) Processing Time\n",
    "processing_time = df_ops.groupby('Job')['Processing Time'].sum()\n",
    "df_jobs = pd.merge(df_jobs, processing_time, on='Job')\n",
    "\n",
    "# d) Bestimmung des Slacks\n",
    "df_jobs['Slack'] = df_jobs['Deadline'] - (df_jobs['Ready Time'] + df_jobs['Processing Time'])\n",
    "\n",
    "# e) Anpassung der Deadlines\n",
    "min_slack = df_jobs['Slack'].min()\n",
    "\n",
    "if min_slack < 0:\n",
    "    df_jobs[\"Deadline\"] = df_jobs[\"Deadline\"] + abs(min_slack)\n",
    "df_jobs\n",
    "\n",
    "# f) erneute Bestimmung des Slacks\n",
    "df_jobs['Slack'] = df_jobs['Deadline'] - (df_jobs['Ready Time'] + df_jobs['Processing Time'])\n",
    "df_jobs "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7da2c8f5-2399-4404-8114-79042a08e6d3",
   "metadata": {},
   "source": [
    "day_length = 1440"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a0ae21915147fa5",
   "metadata": {},
   "source": [
    "## I) Tag 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "04776d25-4938-4628-9b10-e5528285f76e",
   "metadata": {},
   "source": [
    "day_numb = 1\n",
    "\n",
    "day_start = day_length*day_numb \n",
    "day_end = day_start + day_length\n",
    "print(f\"Tag {day_numb:02d}: [{day_start}, {day_end})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "637281af-4ac8-481a-ab73-2b11e24a8cd5",
   "metadata": {},
   "source": [
    "def filter_ops_and_jobs_by_ready_time(df_jobs: pd.DataFrame, df_ops: pd.DataFrame, \n",
    "                              ready_time_col = \"Ready Time\", ready_time: int = 0) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    # Jobs zeitlich filtern\n",
    "    time_filter = df_jobs[ready_time_col] == ready_time\n",
    "    df_jobs_filtered = df_jobs[time_filter].copy()\n",
    "\n",
    "    # Operationen nach (gefilterten) Jobs filtern\n",
    "    jobs = df_jobs_filtered[\"Job\"]\n",
    "    df_ops_filtered = df_ops[df_ops[\"Job\"].isin(jobs)].copy()\n",
    "    return df_jobs_filtered, df_ops_filtered"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9453627d-6d60-4163-b5ae-c867f787b033",
   "metadata": {},
   "source": [
    "df_jobs_curr, df_ops_curr = filter_ops_and_jobs_by_ready_time(df_jobs, df_ops, ready_time = day_start)\n",
    "df_jobs_curr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "169b670c-d333-4f64-a6ed-db381fe55864",
   "metadata": {},
   "source": [
    "### A) Scheduling für Tag 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "b975b99a32e0c9",
   "metadata": {},
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "# Scheduling\n",
    "df_plan = solver.solve_cp_jssp_lateness_by_tardiness_and_earliness(df_ops_curr, df_jobs_curr, w_t = 5,\n",
    "                                                                schedule_start = 1440,\n",
    "                                                                msg=False, timeLimit=max_time, gapRel= 0.00)\n",
    "df_plan\n",
    "\n",
    "# Informationen\n",
    "ending_time = time.time()\n",
    "solver_duration = ending_time - starting_time\n",
    "print(f\"\\nScheduling-Dauer: {int(solver_duration // 60)} Minuten und {(solver_duration % 60):.2f} Sekunden.\")\n",
    "df_plan"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f867fe992cdec24b",
   "metadata": {},
   "source": [
    "show.plot_gantt_machines(df_plan)\n",
    "\n",
    "check.is_machine_conflict_free(df_plan)\n",
    "check.is_operation_sequence_correct(df_plan)\n",
    "check.is_job_timing_correct(df_plan)\n",
    "check.is_start_correct(df_plan)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "013c2961-02cc-4454-a10e-2ef710696e47",
   "metadata": {},
   "source": [
    "### B) Aufteilung in heutige und zukünftge Operationen"
   ]
  },
  {
   "cell_type": "code",
   "id": "047caf4a-2e40-4ae0-b1e8-8e1e535200ad",
   "metadata": {},
   "source": [
    "def filter_plan_for_today(df_plan, latest_op_start: int = 0): # exclusive\n",
    "    filt = (df_plan.Start < latest_op_start)\n",
    "    return df_plan[filt].sort_values(by=\"Job\").reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e086e4a-2f66-4926-8d4a-bd8363ad75e7",
   "metadata": {},
   "source": [
    "df_plan_for_sim = filter_plan_for_today(df_plan, latest_op_start = day_end)\n",
    "df_plan_for_sim"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7a76424-4ddc-43fd-868b-5c49bfb2f0e0",
   "metadata": {},
   "source": [
    "def filter_plan_for_future(df_plan, earliest_op_start: int = 0):\n",
    "    filt = (df_plan.Start >= earliest_op_start)\n",
    "    return df_plan[filt].sort_values(by=[\"Job\", \"Start\"]).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a6662c3-b88b-44f4-9af7-e507106e89cc",
   "metadata": {},
   "source": [
    "df_plan_waiting = filter_plan_for_future(df_plan, earliest_op_start = day_end)\n",
    "df_plan_waiting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29de6b6f5fdb1216",
   "metadata": {},
   "source": [
    "### C) Simulation"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d47fad8a87cd228",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "simulation = ProductionDaySimulation(df_plan_for_sim, vc=0.3)\n",
    "df_execution, df_plan_undone = simulation.run(start_time = day_start, end_time=day_end)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "865c984ef6606386",
   "metadata": {},
   "source": [
    "df_plan_undone"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc08c795b3652d8c",
   "metadata": {},
   "source": [
    "if not df_execution.empty:\n",
    "    show.plot_gantt_machines(df_execution, title=f\"Gantt-Diagramm ab Tag {day_numb}\", duration_column=\"Simulated Processing Time\")\n",
    "else:\n",
    "    print(f\"Nothing executed on day {day_numb}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "feb4b5ff-b664-42b6-849d-7833e29c55f8",
   "metadata": {},
   "source": [
    "df_execution"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14248e58beedb4b7",
   "metadata": {},
   "source": [
    "## II) Tag 2\n",
    "> vereinfacht, ohne neu Aufträge (nur der Rest)"
   ]
  },
  {
   "cell_type": "code",
   "id": "896f44b4-9e7a-4f38-91ca-23700063a2e1",
   "metadata": {},
   "source": [
    "day_numb = 2\n",
    "\n",
    "day_start = day_length*day_numb \n",
    "day_end = day_start + day_length\n",
    "print(f\"Tag {day_numb:02d}: [{day_start}, {day_end})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "584b7955-4649-4572-8a43-2f1076ebca33",
   "metadata": {},
   "source": [
    "#### a) Filtern nach der aktuellen \"Ready Time\""
   ]
  },
  {
   "cell_type": "code",
   "id": "cf12f319-17d6-4e39-b0d1-7ce27df4beb1",
   "metadata": {},
   "source": [
    "df_jobs_curr, df_ops_curr = filter_ops_and_jobs_by_ready_time(df_jobs, df_ops, ready_time = day_start)\n",
    "df_jobs_curr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7cf333c-c30d-4137-9897-1902bcc1ed76",
   "metadata": {},
   "source": [
    "### b) Operationen, die zuvor \"ready\" waren, aber noch nicht starten sollten"
   ]
  },
  {
   "cell_type": "code",
   "id": "1175fa1c-66e9-44bf-a053-9f163fe4f529",
   "metadata": {},
   "source": [
    "df_plan_waiting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcb1061f-7c8f-4e7e-9a7e-c58e73706f93",
   "metadata": {},
   "source": [
    "# Sicherstellen, dass beide DataFrames die Spalten 'Job' und 'Operation' haben\n",
    "df_ops_waiting = df_ops.merge(df_plan_waiting[[\"Job\", \"Operation\"]], on=[\"Job\", \"Operation\"], how=\"inner\")\n",
    "df_ops_waiting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47098840-311e-4517-909b-2aac0047ef11",
   "metadata": {},
   "source": [
    "df_jobs_waiting = df_jobs[df_jobs[\"Job\"].isin(df_plan_waiting[\"Job\"].unique())]\n",
    "df_jobs_waiting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5dde760c-ca03-4cdc-bd74-501f6a03aa36",
   "metadata": {},
   "source": [
    "#### c) Unerledigte Operationen"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2e3deab-feb8-495b-aab1-b266ba4a84af",
   "metadata": {},
   "source": [
    "df_plan_undone"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "494b6e6e-4efd-4445-adf9-69de48a0c333",
   "metadata": {},
   "source": [
    "# Sicherstellen, dass beide DataFrames die Spalten 'Job' und 'Operation' haben\n",
    "df_ops_undone = df_ops.merge(df_plan_undone[[\"Job\", \"Operation\"]], on=[\"Job\", \"Operation\"], how=\"inner\")\n",
    "df_ops_undone"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4fc8575-4925-40f9-a61c-71875b9081a2",
   "metadata": {},
   "source": [
    "df_jobs_undone = df_jobs[df_jobs[\"Job\"].isin(df_ops_undone[\"Job\"].unique())]\n",
    "df_jobs_undone"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "283bba15-bf89-473d-8b74-8de4ab01e2c0",
   "metadata": {},
   "source": [
    "### Zusammenführen"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2a81c19-a143-4f15-899e-bd8c5647f722",
   "metadata": {},
   "source": [
    "# Operationen\n",
    "df_ops_curr_all = pd.concat([df_ops_curr, df_ops_waiting, df_ops_undone], ignore_index=True)\n",
    "df_ops_curr_all = df_ops_curr_all.sort_values(by=[\"Job\", \"Operation\"]).reset_index(drop=True)\n",
    "df_ops_curr_all"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f91494e-42c9-419e-9859-739a464e6e9f",
   "metadata": {},
   "source": [
    "df_jobs_curr_all = pd.concat([df_jobs_curr, df_jobs_waiting, df_jobs_undone], ignore_index=True)\n",
    "df_jobs_curr_all = df_jobs_curr_all.drop_duplicates(subset=\"Job\", keep=\"first\").sort_values(by=\"Job\").reset_index(drop=True)\n",
    "df_jobs_curr_all"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c10d4701-dc84-4f4e-82c7-c2b65684408f",
   "metadata": {},
   "source": [
    "### Prev. Plan "
   ]
  },
  {
   "cell_type": "code",
   "id": "6b731765-3f70-4816-8886-edecace5dfec",
   "metadata": {},
   "source": [
    "df_plan_prev = pd.concat([df_plan_waiting, df_plan_undone]).sort_values(by=[\"Job\", \"Start\"]).reset_index(drop=True)\n",
    "df_plan_prev"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0e6b6a97-8803-4713-956f-30d2b4f6cbf1",
   "metadata": {},
   "source": [
    "### A) Rescheduling für Tag 2"
   ]
  },
  {
   "cell_type": "code",
   "id": "7961e5d3a98a0d15",
   "metadata": {},
   "source": [
    "# Reduktion der bereits ausgeführten Operationen, die im heutigen Plan hineinlaufen\n",
    "df_execution_important = df_execution[df_execution[\"End\"] >= day_start]\n",
    "df_execution_important"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb1de04cbfd3dbf9",
   "metadata": {},
   "source": [
    "def solve_cp_jssp_lateness_by_tardiness_and_earliness_with_devpen(\n",
    "    df_jssp: pd.DataFrame,\n",
    "    df_arrivals_deadlines: pd.DataFrame,\n",
    "    df_executed: pd.DataFrame,\n",
    "    df_original_plan: pd.DataFrame,\n",
    "    w_t: int = 5,\n",
    "    w_e: int = 1,\n",
    "    r: float = 0.5,\n",
    "    reschedule_start: float = 1440.0,\n",
    "    sort_ascending: bool = False,\n",
    "    msg: bool = False,\n",
    "    timeLimit: int = 3600,\n",
    "    gapRel: float = 0.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Solves a Job-Shop Scheduling Problem using Constraint Programming with:\n",
    "    - weighted tardiness,\n",
    "    - earliness,\n",
    "    - deviation penalty from a given reference plan (df_original_plan).\n",
    "\n",
    "    Only deviations for operations present in both df_jssp and df_original_plan are considered.\n",
    "\n",
    "    Parameters:\n",
    "        df_jssp: Job-Shop structure with ['Job','Operation','Machine','Processing Time']\n",
    "        df_arrivals_deadlines: Arrival and Deadline info per Job\n",
    "        df_executed: Already executed operations\n",
    "        df_original_plan: Reference plan with original start times\n",
    "        w_t, w_e: Weights for tardiness and earliness\n",
    "        r: Relative weight between lateness and deviation (0–1)\n",
    "        reschedule_start: Planning starts from this time onward\n",
    "        sort_ascending: Sort jobs by deadline ascending (default: False)\n",
    "        msg: Verbose solver output\n",
    "        timeLimit: Max solver time in seconds\n",
    "        gapRel: Relative gap limit\n",
    "\n",
    "    Returns:\n",
    "        df_schedule: A DataFrame with scheduled operations and timing info\n",
    "    \"\"\"\n",
    "\n",
    "    model = cp_model.CpModel()\n",
    "    w_t = int(w_t)\n",
    "    w_e = int(w_e)\n",
    "    r_scaled = int(round(r * 100))  # scaled for integer arithmetic\n",
    "\n",
    "    # === Vorbereitung: Ankunft, Deadline, Jobliste ===\n",
    "    df_arrivals_deadlines = df_arrivals_deadlines.sort_values(\"Deadline\", ascending=sort_ascending).reset_index(drop=True)\n",
    "    arrival = df_arrivals_deadlines.set_index(\"Job\")[\"Arrival\"].to_dict()\n",
    "    deadline = df_arrivals_deadlines.set_index(\"Job\")[\"Deadline\"].to_dict()\n",
    "    jobs = df_arrivals_deadlines[\"Job\"].tolist()\n",
    "\n",
    "    # === Relevante Deviation-Paare bestimmen ===\n",
    "    deviation_relevant_ops = set(\n",
    "        df_jssp[[\"Job\", \"Operation\"]].apply(tuple, axis=1)\n",
    "    ) & set(\n",
    "        df_original_plan[[\"Job\", \"Operation\"]].apply(tuple, axis=1)\n",
    "    )\n",
    "\n",
    "    original_start = {\n",
    "        (row[\"Job\"], row[\"Operation\"]): int(round(row[\"Start\"]))\n",
    "        for _, row in df_original_plan.iterrows()\n",
    "        if (row[\"Job\"], row[\"Operation\"]) in deviation_relevant_ops\n",
    "    }\n",
    "\n",
    "    # === Operationen strukturieren ===\n",
    "    ops_grouped = df_jssp.sort_values([\"Job\", \"Operation\"]).groupby(\"Job\")\n",
    "    all_ops, machines = [], set()\n",
    "    for job in jobs:\n",
    "        seq = []\n",
    "        for _, row in ops_grouped.get_group(job).iterrows():\n",
    "            op_id = int(row[\"Operation\"])\n",
    "            m = str(row[\"Machine\"])\n",
    "            d = int(round(row[\"Processing Time\"]))\n",
    "            seq.append((op_id, m, d))\n",
    "            machines.add(m)\n",
    "        all_ops.append(seq)\n",
    "\n",
    "    # === Planungshorizont abschätzen ===\n",
    "    horizon = int(df_jssp[\"Processing Time\"].sum() + max(deadline.values()))\n",
    "\n",
    "    # === Fixierte Operationen berücksichtigen ===\n",
    "    df_executed_fixed = df_executed[df_executed[\"End\"] >= reschedule_start]\n",
    "    fixed_ops = {\n",
    "        m: list(grp[[\"Start\", \"End\"]].itertuples(index=False, name=None))\n",
    "        for m, grp in df_executed_fixed.groupby(\"Machine\")\n",
    "    }\n",
    "    last_executed_end = df_executed.groupby(\"Job\")[\"End\"].max().to_dict()\n",
    "\n",
    "    # === Variablen definieren ===\n",
    "    starts, ends, intervals = {}, {}, {}\n",
    "    weighted_terms = []\n",
    "    deviation_terms = []\n",
    "\n",
    "    for j, job in enumerate(jobs):\n",
    "        for o, (op_id, m, d) in enumerate(all_ops[j]):\n",
    "            suffix = f\"{j}_{o}\"\n",
    "            start = model.NewIntVar(0, horizon, f\"start_{suffix}\")\n",
    "            end = model.NewIntVar(0, horizon, f\"end_{suffix}\")\n",
    "            interval = model.NewIntervalVar(start, d, end, f\"interval_{suffix}\")\n",
    "            starts[(j, o)] = start\n",
    "            ends[(j, o)] = end\n",
    "            intervals[(j, o)] = (interval, m)\n",
    "\n",
    "    # === Constraints und Zielterme ===\n",
    "    for j, job in enumerate(jobs):\n",
    "        last_op_index = len(all_ops[j]) - 1\n",
    "        job_end = ends[(j, last_op_index)]\n",
    "\n",
    "        # Lateness = End - Deadline\n",
    "        lateness = model.NewIntVar(-horizon, horizon, f\"lateness_{j}\")\n",
    "        model.Add(lateness == job_end - deadline[job])\n",
    "\n",
    "        # Tardiness\n",
    "        tardiness = model.NewIntVar(0, horizon, f\"tardiness_{j}\")\n",
    "        model.AddMaxEquality(tardiness, [lateness, 0])\n",
    "        term_tardiness = model.NewIntVar(0, horizon * w_t, f\"term_tardiness_{j}\")\n",
    "        model.Add(term_tardiness == w_t * tardiness)\n",
    "        weighted_terms.append(term_tardiness)\n",
    "\n",
    "        # Earliness\n",
    "        earliness = model.NewIntVar(0, horizon, f\"earliness_{j}\")\n",
    "        model.AddMaxEquality(earliness, [-lateness, 0])\n",
    "        term_earliness = model.NewIntVar(0, horizon * w_e, f\"term_earliness_{j}\")\n",
    "        model.Add(term_earliness == w_e * earliness)\n",
    "        weighted_terms.append(term_earliness)\n",
    "\n",
    "        # Startzeitbedingungen\n",
    "        model.Add(starts[(j, 0)] >= max(arrival[job], int(reschedule_start)))\n",
    "        if job in last_executed_end:\n",
    "            model.Add(starts[(j, 0)] >= int(math.ceil(last_executed_end[job])))\n",
    "\n",
    "        # Technologische Reihenfolge\n",
    "        for o in range(1, len(all_ops[j])):\n",
    "            model.Add(starts[(j, o)] >= ends[(j, o - 1)])\n",
    "\n",
    "        # Deviation: nur für relevante Ops\n",
    "        for o, (op_id, _, _) in enumerate(all_ops[j]):\n",
    "            key = (job, op_id)\n",
    "            if key in original_start:\n",
    "                dev = model.NewIntVar(0, horizon, f\"dev_{j}_{o}\")\n",
    "                diff = model.NewIntVar(-horizon, horizon, f\"diff_{j}_{o}\")\n",
    "                model.Add(diff == starts[(j, o)] - original_start[key])\n",
    "                model.AddAbsEquality(dev, diff)\n",
    "                deviation_terms.append(dev)\n",
    "\n",
    "    # === Maschinenrestriktionen (inkl. fixierter Intervalle) ===\n",
    "    for m in machines:\n",
    "        machine_intervals = [interval for (j, o), (interval, mach) in intervals.items() if mach == m]\n",
    "        for fixed_start, fixed_end in fixed_ops.get(m, []):\n",
    "            start = math.floor(fixed_start)\n",
    "            end = math.ceil(fixed_end)\n",
    "            duration = end - start\n",
    "            if duration > 0:\n",
    "                fixed_interval = model.NewIntervalVar(start, duration, end, f\"fixed_{m}_{end}\")\n",
    "                machine_intervals.append(fixed_interval)\n",
    "        model.AddNoOverlap(machine_intervals)\n",
    "\n",
    "    # === Zielfunktion kombinieren ===\n",
    "    weighted_part = model.NewIntVar(0, horizon * len(weighted_terms), \"weighted_part\")\n",
    "    deviation_part = model.NewIntVar(0, horizon * len(deviation_terms), \"deviation_part\")\n",
    "    model.Add(weighted_part == sum(weighted_terms))\n",
    "    model.Add(deviation_part == sum(deviation_terms))\n",
    "\n",
    "    total_cost = model.NewIntVar(0, horizon * len(jobs) * 100, \"total_cost\")\n",
    "    model.Add(total_cost == r_scaled * weighted_part + (100 - r_scaled) * deviation_part)\n",
    "    model.Minimize(total_cost)\n",
    "\n",
    "    # === Solver-Einstellungen ===\n",
    "    solver = cp_model.CpSolver()\n",
    "    solver.parameters.log_search_progress = msg\n",
    "    solver.parameters.max_time_in_seconds = timeLimit\n",
    "    solver.parameters.relative_gap_limit = gapRel\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # === Ergebnis extrahieren ===\n",
    "    records = []\n",
    "    if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:\n",
    "        for j, job in enumerate(jobs):\n",
    "            for o, (op_id, m, d) in enumerate(all_ops[j]):\n",
    "                st = solver.Value(starts[(j, o)])\n",
    "                ed = st + d\n",
    "                lateness_val = ed - deadline[job]\n",
    "                records.append({\n",
    "                    \"Job\": job,\n",
    "                    \"Operation\": op_id,\n",
    "                    \"Arrival\": arrival[job],\n",
    "                    \"Deadline\": deadline[job],\n",
    "                    \"Machine\": m,\n",
    "                    \"Start\": st,\n",
    "                    \"Processing Time\": d,\n",
    "                    \"End\": ed,\n",
    "                    \"Lateness\": lateness_val,\n",
    "                    \"Tardiness\": max(0, lateness_val),\n",
    "                    \"Earliness\": max(0, -lateness_val)\n",
    "                })\n",
    "\n",
    "        df_schedule = pd.DataFrame.from_records(records).sort_values([\"Start\", \"Job\", \"Operation\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"\\nSolver-Status         : {solver.StatusName(status)}\")\n",
    "        print(\"No feasible solution found!\")\n",
    "        df_schedule = pd.DataFrame()\n",
    "\n",
    "    # === Logging ===\n",
    "    print(f\"\\nSolver-Status         : {solver.StatusName(status)}\")\n",
    "    print(f\"Objective Value       : {solver.ObjectiveValue():.2f}\")\n",
    "    print(f\"Best Objective Bound  : {solver.BestObjectiveBound():.2f}\")\n",
    "    print(f\"Laufzeit              : {solver.WallTime():.2f} Sekunden\")\n",
    "    print(f\"Deviation terms       : {len(deviation_terms)}\")\n",
    "\n",
    "    return df_schedule"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71a698b9768002c9",
   "metadata": {},
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "df_reschedule = solve_cp_jssp_lateness_by_tardiness_and_earliness_with_devpen(df_ops_curr_all, df_jobs_curr_all, \n",
    "                                                                              df_execution_important,\n",
    "                                                                              df_original_plan = df_plan_prev,\n",
    "                                                                              w_t = 5,\n",
    "                                                                              r = 0.70, # 70% Lateness, 30% Deviation\n",
    "                                                                              reschedule_start = day_start,\n",
    "                                                                              msg=False, timeLimit=max_time, gapRel= 0.01)\n",
    "# Informationen\n",
    "ending_time = time.time()\n",
    "solver_duration = ending_time - starting_time\n",
    "print(f\"\\nScheduling-Dauer: {int(solver_duration // 60)} Minuten und {(solver_duration % 60):.2f} Sekunden.\")\n",
    "df_reschedule"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d54c59129c8bf220",
   "metadata": {},
   "source": [
    "show.plot_gantt_machines(df_reschedule)\n",
    "check.is_machine_conflict_free(df_reschedule)\n",
    "check.is_operation_sequence_correct(df_reschedule)\n",
    "check.is_job_timing_correct(df_reschedule)\n",
    "check.is_start_correct(df_reschedule)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d613e12ac2643f1e",
   "metadata": {},
   "source": [
    "last_ops = df_reschedule.sort_values(['Job', 'Operation']).drop_duplicates('Job', keep='last')\n",
    "show.count_column_grouped(last_ops, \"Lateness\", max_val = 180, steps= 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2778158e-3e24-49f8-a5d0-2e4d56c22562",
   "metadata": {},
   "source": [
    " df_execution[df_execution.Job == \"Job_011\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d2921a0-8be1-41f4-907b-4f5f3cfa9f9c",
   "metadata": {},
   "source": [
    "df_reschedule[df_reschedule.Job == \"Job_011\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65543ba776ec92ac",
   "metadata": {},
   "source": [
    "### Combi aus Simulation und Neuplannung"
   ]
  },
  {
   "cell_type": "code",
   "id": "b01494dfa39197f8",
   "metadata": {},
   "source": [
    "# Relevante Spalten\n",
    "columns_needed = [\"Job\", \"Operation\", \"Arrival\", \"Machine\", \"Start\", \"Processing Time\", \"End\"]\n",
    "\n",
    "# Spalte in df_execution umbenennen\n",
    "df_execution_important_renamed = df_execution.rename(columns={\"Simulated Processing Time\": \"Processing Time\"})\n",
    "\n",
    "# Auf die gewünschten Spalten beschränken\n",
    "df_exec_trimmed = df_execution_important_renamed[columns_needed]\n",
    "df_resched_trimmed = df_reschedule[columns_needed]\n",
    "\n",
    "# DataFrames zusammenführen\n",
    "df_combined = pd.concat([df_exec_trimmed, df_resched_trimmed], ignore_index=True)\n",
    "df_combined"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f42c27a4a1a70039",
   "metadata": {},
   "source": [
    "show.plot_gantt_machines(df_combined)\n",
    "check.is_machine_conflict_free(df_combined)\n",
    "check.is_operation_sequence_correct(df_combined)\n",
    "check.is_job_timing_correct(df_combined)\n",
    "check.is_start_correct(df_combined)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
